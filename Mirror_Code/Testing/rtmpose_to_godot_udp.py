#!/usr/bin/env python3
"""
Real-time bridge: RTMPose keypoints -> avatar bone quaternions over UDP (Godot-friendly).

Run this from Testing with rtmpose_env:
  ./rtmpose_env/bin/python rtmpose_to_godot_udp.py --retarget-config human_body_autorig.retarget.json
"""

from __future__ import annotations

import argparse
import json
import socket
import time
from collections import deque
from pathlib import Path
from typing import Dict, Tuple

import cv2
import numpy as np

import rtmpose_realtime as rt


def normalize(v: np.ndarray) -> np.ndarray:
    n = float(np.linalg.norm(v))
    if n < 1e-8:
        return np.array([0.0, 0.0, 0.0], dtype=np.float32)
    return (v / n).astype(np.float32)


def quat_from_two_vectors(v_from: np.ndarray, v_to: np.ndarray) -> np.ndarray:
    a = normalize(v_from)
    b = normalize(v_to)
    dot = float(np.clip(np.dot(a, b), -1.0, 1.0))
    if dot > 0.999999:
        return np.array([1.0, 0.0, 0.0, 0.0], dtype=np.float32)
    if dot < -0.999999:
        axis = normalize(np.cross(a, np.array([1.0, 0.0, 0.0], dtype=np.float32)))
        if np.linalg.norm(axis) < 1e-6:
            axis = normalize(np.cross(a, np.array([0.0, 1.0, 0.0], dtype=np.float32)))
        return np.array([0.0, axis[0], axis[1], axis[2]], dtype=np.float32)
    axis = normalize(np.cross(a, b))
    s = np.sqrt((1.0 + dot) * 2.0)
    inv_s = 1.0 / max(s, 1e-8)
    q = np.array(
        [0.5 * s, axis[0] * inv_s, axis[1] * inv_s, axis[2] * inv_s],
        dtype=np.float32,
    )
    return q / max(np.linalg.norm(q), 1e-8)


def quat_nlerp(prev_q: np.ndarray, curr_q: np.ndarray, alpha: float) -> np.ndarray:
    # Flip to same hemisphere to avoid long-path interpolation.
    if float(np.dot(prev_q, curr_q)) < 0.0:
        curr_q = -curr_q
    q = alpha * prev_q + (1.0 - alpha) * curr_q
    n = float(np.linalg.norm(q))
    if n < 1e-8:
        return curr_q
    return (q / n).astype(np.float32)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="RTMPose to Godot UDP retarget stream")
    parser.add_argument(
        "--retarget-config",
        type=str,
        default="human_body_autorig.retarget.json",
        help="Retarget JSON generated by generate_retarget_config.py",
    )
    parser.add_argument("--camera-id", type=int, default=0, help="OpenCV camera index")
    parser.add_argument(
        "--camera-backend",
        type=str,
        default="auto",
        choices=("auto", "default", "v4l2", "avfoundation"),
        help="Camera backend selection",
    )
    parser.add_argument("--width", type=int, default=640, help="Requested camera width")
    parser.add_argument("--height", type=int, default=480, help="Requested camera height")
    parser.add_argument("--kpt-thr", type=float, default=0.35, help="Keypoint confidence threshold")
    parser.add_argument(
        "--quat-smooth-alpha",
        type=float,
        default=0.80,
        help="Quaternion smoothing alpha (0=no smoothing, 0.95=strong smoothing)",
    )
    parser.add_argument(
        "--hold-missing-frames",
        type=int,
        default=8,
        help="How many frames to keep previous bone rotation if keypoints are missing",
    )
    parser.add_argument("--udp-host", type=str, default="127.0.0.1", help="UDP destination host")
    parser.add_argument("--udp-port", type=int, default=7000, help="UDP destination port")
    parser.add_argument(
        "--packet-json",
        type=str,
        default="",
        help="Optional output file to write latest packet JSON for debug",
    )
    parser.add_argument("--cpu-threads", type=int, default=2, help="CPU thread cap")
    parser.add_argument("--opencv-threads", type=int, default=1, help="OpenCV thread cap")
    parser.add_argument("--show-preview", action="store_true", help="Show annotated camera preview")
    parser.add_argument("--show-fps", action="store_true", help="Overlay moving-average FPS")
    return parser.parse_args()


def load_retarget(path: Path) -> Dict:
    data = json.loads(path.read_text(encoding="utf-8"))
    if "bone_slots" not in data:
        raise RuntimeError("Invalid retarget config: missing 'bone_slots'.")
    return data


def select_primary_person(scores: np.ndarray, kpt_thr: float) -> int:
    # Prefer person with highest torso visibility and overall confidence.
    if scores.ndim == 1:
        return 0
    torso_ids = [5, 6, 11, 12]
    best_i = 0
    best_score = -1.0
    for i in range(scores.shape[0]):
        torso_score = float(np.sum(scores[i, torso_ids]))
        vis_bonus = float(np.sum(scores[i] > kpt_thr)) * 0.05
        metric = torso_score + vis_bonus
        if metric > best_score:
            best_score = metric
            best_i = i
    return best_i


def chain_definitions(slots: Dict[str, str]) -> Dict[str, Tuple[str, int, int]]:
    return {
        "left_upper_arm": (slots.get("left_upper_arm"), 5, 7),
        "left_lower_arm": (slots.get("left_lower_arm"), 7, 9),
        "right_upper_arm": (slots.get("right_upper_arm"), 6, 8),
        "right_lower_arm": (slots.get("right_lower_arm"), 8, 10),
        "left_upper_leg": (slots.get("left_upper_leg"), 11, 13),
        "left_lower_leg": (slots.get("left_lower_leg"), 13, 15),
        "right_upper_leg": (slots.get("right_upper_leg"), 12, 14),
        "right_lower_leg": (slots.get("right_lower_leg"), 14, 16),
    }


def main() -> int:
    args = parse_args()
    args.quat_smooth_alpha = min(max(args.quat_smooth_alpha, 0.0), 0.98)
    args.hold_missing_frames = max(int(args.hold_missing_frames), 0)
    args.kpt_thr = float(args.kpt_thr)

    retarget_path = Path(args.retarget_config).expanduser().resolve()
    cfg = load_retarget(retarget_path)
    slots = cfg["bone_slots"]
    chains = chain_definitions(slots)

    rt._configure_cpu_runtime(int(args.cpu_threads), int(args.opencv_threads))
    runtime = rt.RTMPoseCPURuntime(
        argparse.Namespace(
            det_frequency=4,
            no_tracking=False,
            mode="lightweight",
            det_score_thr=0.8,
            kpt_thr=args.kpt_thr,
            smooth_alpha=0.65,
            infer_every=2,
        )
    )

    cap = rt._open_camera(int(args.camera_id), args.camera_backend)
    if not cap.isOpened():
        raise RuntimeError(f"Could not open camera index {args.camera_id}.")
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, int(args.width))
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, int(args.height))
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    dest = (args.udp_host, int(args.udp_port))

    prev_quat: Dict[str, np.ndarray] = {}
    missing_count: Dict[str, int] = {}
    fps_window = deque(maxlen=60)
    last_t = None

    window_name = "RTMPose -> Godot UDP (q/esc to quit)"
    default_bone_axis = np.array([0.0, 1.0, 0.0], dtype=np.float32)

    try:
        while True:
            t0 = time.perf_counter()
            ok, frame = cap.read()
            if not ok:
                continue

            try:
                keypoints, scores = runtime.infer(frame)
            except Exception:
                keypoints = np.empty((0, 17, 2), dtype=np.float32)
                scores = np.empty((0, 17), dtype=np.float32)

            bones_payload: Dict[str, Dict] = {}
            active_keypoints = None
            active_scores = None

            if isinstance(keypoints, np.ndarray) and keypoints.size > 0:
                if keypoints.ndim == 2:
                    keypoints = keypoints[None, ...]
                if scores.ndim == 1:
                    scores = scores[None, ...]

                person_idx = select_primary_person(scores, args.kpt_thr)
                active_keypoints = keypoints[person_idx].astype(np.float32)
                active_scores = scores[person_idx].astype(np.float32)

                for _, (bone_name, src_idx, dst_idx) in chains.items():
                    if not bone_name:
                        continue
                    if src_idx >= active_keypoints.shape[0] or dst_idx >= active_keypoints.shape[0]:
                        continue

                    src_conf = float(active_scores[src_idx]) if dst_idx < active_scores.shape[0] else 0.0
                    dst_conf = float(active_scores[dst_idx]) if dst_idx < active_scores.shape[0] else 0.0
                    conf = min(src_conf, dst_conf)

                    if conf >= args.kpt_thr:
                        src = active_keypoints[src_idx]
                        dst = active_keypoints[dst_idx]
                        v = np.array([dst[0] - src[0], dst[1] - src[1], 0.0], dtype=np.float32)
                        if np.linalg.norm(v) > 1e-6:
                            q = quat_from_two_vectors(default_bone_axis, v)
                            if bone_name in prev_quat and args.quat_smooth_alpha > 0.0:
                                q = quat_nlerp(prev_quat[bone_name], q, args.quat_smooth_alpha)
                            prev_quat[bone_name] = q
                            missing_count[bone_name] = 0
                            bones_payload[bone_name] = {
                                "rotation_quat_wxyz": [float(x) for x in q],
                                "confidence": conf,
                            }
                            continue

                    # Missing point handling.
                    miss = missing_count.get(bone_name, 0) + 1
                    missing_count[bone_name] = miss
                    if bone_name in prev_quat and miss <= args.hold_missing_frames:
                        q_prev = prev_quat[bone_name]
                        held_conf = max(0.05, 0.5 * (1.0 - (miss / max(1, args.hold_missing_frames))))
                        bones_payload[bone_name] = {
                            "rotation_quat_wxyz": [float(x) for x in q_prev],
                            "confidence": held_conf,
                            "inferred": True,
                        }

            packet = {
                "ts_unix": time.time(),
                "source": "rtmpose_to_godot_udp",
                "asset": cfg.get("asset_glb"),
                "bones": bones_payload,
            }
            payload = json.dumps(packet, separators=(",", ":"), ensure_ascii=True).encode("utf-8")
            sock.sendto(payload, dest)

            if args.packet_json:
                packet_path = Path(args.packet_json).expanduser().resolve()
                packet_path.write_text(json.dumps(packet, indent=2) + "\n", encoding="utf-8")

            if args.show_preview:
                if active_keypoints is not None and active_scores is not None:
                    frame = rt._draw_pose(
                        frame,
                        active_keypoints[None, ...],
                        active_scores[None, ...],
                        args.kpt_thr,
                    )
                    cv2.putText(
                        frame,
                        f"bones sent: {len(bones_payload)}",
                        (12, 28),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.65,
                        (0, 255, 0),
                        2,
                        cv2.LINE_AA,
                    )
                else:
                    cv2.putText(
                        frame,
                        "no person detected",
                        (12, 28),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.65,
                        (0, 180, 255),
                        2,
                        cv2.LINE_AA,
                    )

                if args.show_fps:
                    now = time.perf_counter()
                    if last_t is not None:
                        fps_window.append(now - last_t)
                    last_t = now
                    fps = len(fps_window) / max(sum(fps_window), 1e-6) if fps_window else 0.0
                    cv2.putText(
                        frame,
                        f"FPS: {fps:.1f} UDP {args.udp_host}:{args.udp_port}",
                        (12, 56),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (230, 230, 230),
                        2,
                        cv2.LINE_AA,
                    )

                cv2.imshow(window_name, frame)
                key = cv2.waitKey(1) & 0xFF
                if key in (ord("q"), 27):
                    break

            # Keep loop from spinning too hard if preview is off.
            if not args.show_preview:
                elapsed = time.perf_counter() - t0
                if elapsed < 0.005:
                    time.sleep(0.005 - elapsed)
    finally:
        cap.release()
        cv2.destroyAllWindows()
        sock.close()

    return 0


if __name__ == "__main__":
    raise SystemExit(main())

